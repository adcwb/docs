### 一、爬虫简介

```python
什么是爬虫：
	通过编写程序，让其模拟浏览器上网，然后去互联网上爬取数据的过程。
    	模拟：
        	- 所谓的浏览器就是一款纯天然爬虫工具
        爬取：
            - 抓取到一张页面的一整张的数据
            - 抓取页面中的局部数据
            
爬虫在使用场景中的分类：
	- 通用爬虫
        - 需要将页面的一整张数据进行爬取
    - 聚焦爬虫
        - 需要将页面中局部的指定的数据进行爬取
        - 关联：聚焦爬虫是需要建立在通用爬虫基础之上。
    - 增量式爬虫
        - 用于检测网站数据更新的情况。爬取网站中最新更新出来的数据。
    - 分布式爬虫
        - 搭建一个分布式机群，可以快速的进行海量数据的爬取
        
爬虫的合法性探究：
	如果你的爬虫程序没有影响对方网站的正常运行且没有爬取相关涉及侵权的数据。
    
爬虫的核心
	反爬机制：
		- 门户网站在服务器端会设置一些机制或者策略来组织爬虫进行数据的爬取。
	反反爬策略：
		- 爬虫需要破解网站指定的反爬机制从而爬取到网站的数据。
```

### 二、Anaconda

```python
Anaconda：是一个基于数据分析+机器学习的集成环境。
anadonda安装注意事项:
    > 安装路径中不可以出现中文和特殊符号
    > 安装时要勾选环境变量
jupyter：Anaconda提供的一个基于浏览器可视化的编码工具。
	安装了anaconda后，需要在终端中录入jupyter notebook指令。
	注意：jupyter notebook指令对应的终端目录就是jupyter启动后的根目录

jupyter的基本操作：
	.ipynb：jupyter中的一个源文件，代码的编写就要基于该源文件。该源文件是由cell组成的
    
cell的使用
	cell是分成了两种不同的模式：
	code：用来编写程序的
    	注意：代码编写不分上下，代码的执行分先后
	markdown：用来编写笔记
快捷键：
	添加cell：a上插入cell，b下插入cell
	删除cell：x
    撤销：z
	执行cell：shift+enter
	切换cell的模式：
		code-》markdown：m
		反之：y
	查看帮助文档：shift+tab
```



